
Pseudo code for file system walker.

Overall goal is to iterate over $backup_dirs and notice any deleted,
modified, or created files/directories.  Then build a queue of the
changed files sorted by inode.

First note the time of the start of the backup.

Please note in the common case (most files already backed up)
it does one SQL statement per directory.

// NOT a go routine
queueROWID(db, rowBuf, ROWID, config.SQLBuffer)
{
	if (len(rowBuf)<MAXBuffSize)
	{ 
		rowBuf=append(fiBuf,fi)
	}
	else
	{
		db.Begin()
		for i:=0; i<MAXBuffSize; i++
		{
			// add the file and set NeedsToBeUploaded = True
			db.prepare ("update files set ToUpload=False where ROWID=$ROWID)
			db.exec	
		}
		db.Commit()
		// zero fiBuf
	}
}


func queue_file ( db, fiBuf, fi, MAXBuffSize)
{
	if (len(fiBuf)<MAXBuffSize)
	{ 
		fiBuf=append(fiBuf,fi)
	}
	else
	{
		db.Begin()
		for i:=0; i<MAXBuffSize; i++
		{
			// add the file and set NeedsToBeUploaded = True
			db.prepare ("insert into files .... ",fiBuf[i]....
			db.exec	
		}
		db.Commit()
		// zero fiBuf
	}
}

// interate through the directory array
for i < len(dirArray)
{
	// inside add_dir_to_sql should only insert if dir isn't in sql
	add_dir_to_sql(i)

	// build list of files in this directory
	d, err := os.Open(dirname)
	fi, err := d.Readdir(-1)

	// build list of files from sql
	sqlList  = get_list_of_files_in_dir(i)

	// iterate over list of files in current directory
    // fibuf is allocated here only so it is preserved
    // across called to queue_file, if possible
    // move this inside queue_file
    fiBuf=make(fi,config.SQLBuffer)
	for _, fi := range fi {
		if !fi.IsDir() {
			// modtime = zero if file not in SQL.
			modtime := get_modified_time(sqllist(fi.Name))
			// compare the local modified time for this file to the one in sql
			if fi.Modified_time > modtime
				queue_file(db, fiBuf, fi, config.SQLBuffer)
			} else {
			// if dir isn't in sql add it 
			// if dir isn't in dirArray append it.
		}
	}
    // Do not add files to SQL until they have been ACTUALLY uploaded
}
closeDB()
// every backup should include an updated metadata database
copy_file(config.sql_file,config.sql_file+".tmp")
append_file(config.sql_file+".tmp");
close("to_upload.txt");
openDB();

UpChannel   = MakeChannel, buffered, 100 x (ROWID, FullPath)
DownChannel = MakeChannel, buffered, 100 x (ROWID, Err)
preBuffer = config.UploadBuffer
res = select * from Files where ToUpload=True

// Preload Channel
while (preBuffer and res)
	UpChannel <- res
	preBuffer--

// Keep Channel Full
while (res)
	UpChannel <- res
	ROWID, Err <-  DownChannel
    if (Err == nil)
	{
		queueROWID(db, rowBuf, ROWID, config.SQLBuffer)
	} else {
		log.Warning("Error uploading %s", err)
	}
}

// Flush channel
while i := range downChannel {
	ROWID, Err <-  DownChannel
    if (Err == nil)
	{
		queueROWID(db, rowBuf, ROWID, config.SQLBuffer)
	} else {
		log.Warning("Error uploading %s", err)
	}
}
	
	

	

go feed_uploader
	res = "select * from files where NeedsToBeUploaded=True	
	while <res>
	{
		send file to Upchannel/Uploader
	}

// launch a go routine to update SQL for each file that was successfully uploaded
go update_sql
	while (fi:=FileHasBeenUploaded(DownChannel)	)
	{
		insert_file(fi)
	}

Once done the encryption queue should be sorted by inode.

Then addDir and addFile are functions that compare what's on the filesystem with what is
in the database:
* BOTH addFile and addDir update last_seen for EVERYTHING it sees.
* NEVER modify a file or directory with metadata from stat, ALWAYS insert.
* Add directory to SQL if missing or modified.
* Adds file to sql if missing,modified metadata, or modified conetns, and queue it for encryption

One key step is that after the above any file with last_seen older than
the start of the current backup must have been deleted and that needs
to be noted.

Something like:
update files set deleted=TRUE where deleted=FALSE and last_seen < $start_of_backup.



 
