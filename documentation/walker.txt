
Pseudo code for file system walker.

Overall goal is to iterate over $backup_dirs and notice any deleted,
modified, or created files/directories.  Then build a queue of the
changed files sorted by inode.

First note the time of the start of the backup.

Please note in the common case (most files already backed up)
it does one SQL statement per directory.

// NOT a go routine
queueROWID(db, rowBuf, ROWID, config.SQLBuffer)
{
	if (len(rowBuf)<MAXBuffSize)
	{ 
		rowBuf=append(fiBuf,fi)
	}
	else
	{
		db.Begin()
		for i:=0; i<MAXBuffSize; i++
		{
			// add the file and set NeedsToBeUploaded = True
			db.prepare ("update files set ToUpload=False where ROWID=$ROWID)
			db.exec	
		}
		db.Commit()
		// zero rowBuf
	}
}

// NOT a go routine
func queue_file ( db, fiBuf, fi, MAXBuffSize)
{
	if (len(fiBuf)<MAXBuffSize)
	{ 
		fiBuf=append(fiBuf,fi)
	}
	else
	{
		db.Begin()
		for i:=0; i<MAXBuffSize; i++
		{
			// add the file and set NeedsToBeUploaded = True
			db.prepare ("insert into files .... ",fiBuf[i]....
			db.exec	
		}
		db.Commit()
		// zero fiBuf
	}
}
// NOT a go routine
func queue_seen( db, seenBuf, fi, timestamp, MAXBuffSize)
{
	if (len(seenBuf)<MAXBuffSize)
	{ 
		seenBuf=append(seenBuf,fi,timestamp)
	}
	else
	{
		db.Begin()
		for i:=0; i<MAXBuffSize; i++
		{
			// add the file and set NeedsToBeUploaded = True
			db.prepare ("update files set lastseen ...", fseenBuf[i]...., timetamp
			db.exec	
		}
		db.Commit()
		// zero  seenBuf
	}
}
// NOT a go routine
func queue_file ( db, seenBuf, fi, MAXBuffSize)
{
	

// interate through the directory array
startTime=gettimeofday() // seconds since 1970
for i < len(dirArray)
{
	// inside add_dir_to_sql should only insert if dir isn't in sql
	add_dir_to_sql(i)

	// build list of files in this directory
	d, err := os.Open(dirname)
	fi, err := d.Readdir(-1)

	// build list of files from sql
	sqlList  = get_list_of_files_in_dir(i)

	// iterate over list of files in current directory
    // fibuf is allocated here only so it is preserved
    // across called to queue_file, if possible
    // move this inside queue_file
    fiBuf=make(fi,config.SQLBuffer)
	for _, fi := range fi {
		if !fi.IsDir() {
			// modtime = zero if file not in SQL.
			modtime := get_modified_time(sqllist(fi.Name))
			// compare the local modified time for this file to the one in sql
			if fi.Modified_time > modtime
				queue_file(db, fiBuf, fi, config.SQLBuffer)
			} else {
				queue_file_seen(db,seenBuf, fi, config.SQLBuffer)
			}
		} else {
			// if dir isn't in sql add it 
			// if dir isn't in dirArray append it.
		}
	}
    // Do not add files to SQL until they have been ACTUALLY uploaded
}
// Any files we don't see must have been deleted.
db.exec("update files set deleted=Y where deleted=N and last_seen<startTime")

closeDB()
// every backup should include an updated metadata database
copy_file(config.sql_file,config.sql_file+".tmp")
append_file(config.sql_file+".tmp");
close("to_upload.txt");
openDB();

UpChannel   = MakeChannel, buffered, 100 x (ROWID, FullPath)
DownChannel = MakeChannel, buffered, 100 x (ROWID, Err)
preBuffer = config.UploadBuffer
res = select * from Files where ToUpload=True order by Inode

// launch goroutine uploader who does NOT have access to SQL/DB directly.
go uploaded(UpChannel,DownChannel,config.MAXTHREADS)
 
// Preload Channel
while (preBuffer and res)
	UpChannel <- res
	preBuffer--

// Keep Channel Full
while (res)
	// likely to block, that's ok.
	UpChannel <- res
	// Will rarely/if ever block
	ROWID, Err <-  DownChannel
    if (Err == nil)
	{
		queueROWID(db, rowBuf, ROWID, config.SQLBuffer)
	} else {
		log.Warning("Error uploading %s", err)
	}
}
// Flush DownChannel now that there's no more files for UpChannel
while i := range downChannel {
	ROWID, Err <-  DownChannel
    if (Err == nil)
	{
		queueROWID(db, rowBuf, ROWID, config.SQLBuffer)
	} else {
		log.Warning("Error uploading %s", err)
	}
}
 
